# Informe DL ML

**DefiniciÃ³n de los roles de la pareja (quiÃ©n hace quÃ©) ğŸ¤**

Los roles dentro de nuestro equipo son los siguientes:

- **Amalia Martin:**
  - Modelos :
  - EvaluaciÃ³n :
  - AutomatizaciÃ³n : ...
- **Carlos Toro:**
  - Modelos : regresiÃ³n lineal, Ã¡rbol de decisiÃ³n, Random Forest, XGBoost
  - EvaluaciÃ³n : regresiÃ³n lineal, Ã¡rbol de decisiÃ³n, Random Forest, XGBoost
  - AutomatizaciÃ³n : Division en scripts

Ambos nos hemos dividido de manera que cada uno pueda abordar todos los aspectos del proyecto, para asegurarnos de aplicar todos los conceptos que hemos aprendido en clase.

**JustificaciÃ³n del problema ğŸ¯**

El problema que estamos abordando con este dataset es calcular cuÃ¡ntas personas cancelan sus reservas en un hotel. Este dataset contiene todos los datos necesarios para analizar y determinar las razones por las cuales alguien decide cancelar su reserva.

**AnÃ¡lisis exploratorio de datos ğŸ“Š**
EDA ...

**DiseÃ±o del sistema ğŸ–¥ï¸**

El proyecto estÃ¡ estructurado de la siguiente manera:

```pyhthon
ML_DL_PONTIA_5/
	â”‚
	â”œâ”€â”€ /data
	â”‚   â”œâ”€â”€ dataset_hotel_preprocessed.csv
		â”œâ”€â”€ dataset_practica_final
		â””â”€â”€ resultado_modelos
	â”œâ”€â”€ /env-entrega-final                        # Entorno virtual
	â”œâ”€â”€ /notebooks
	    â”œâ”€â”€  dl_ml.ipynb
		â””â”€â”€  EDA.ipynb
	â”œâ”€â”€	/process_hotel_model
		â”œâ”€â”€ config.py
		â”œâ”€â”€ trainer.py
		â”œâ”€â”€ data_loader.py
		â”œâ”€â”€ preprocess.py
		â”œâ”€â”€ model.py
		â”œâ”€â”€ metrics.py
	â”œâ”€â”€ /models
	â”‚   â””â”€â”€ modelo_random_forest.pkl
	â”œâ”€â”€ requirements.txt
	â”œâ”€â”€ Informe Final
	â””â”€â”€ README.md
```

**Resultados y elecciÃ³n final ğŸŒŸ**
DespuÃ©s de probar los diferentes modelos hemos decidido que el mejor es el modelo de **XGBoost**

### ğŸ“Š **Comparativa rÃ¡pida de los modelos:**

| Modelo                 | Accuracy  | PrecisiÃ³n | Recall    | F1-Score  | AUC       |
| ---------------------- | --------- | --------- | --------- | --------- | --------- |
| RegresiÃ³n LogÃ­stica    | 0.758     | 0.655     | 0.254     | 0.366     | 0.756     |
| Ãrbol de DecisiÃ³n      | 0.757     | 0.638     | 0.253     | 0.362     | 0.757     |
| Random Forest          | 0.757     | 0.638     | 0.253     | 0.362     | 0.757     |
| **XGBoost**            | **0.783** | **0.681** | **0.399** | **0.503** | **0.802** |
| Red Neuronal Multicapa | 0.780     | 0.676     | 0.386     | 0.491     | 0.802     |

**Â¿Por quÃ© hemos elegido XGBoost?**

La mÃ©trica mas determinante de nuestros modelos es el F1-score, al ser la media de recall (el cual es alto, lo que nos permite identificar un mayor porcentaje de reservas que se cancelarÃ¡n) y precisiÃ³n. XGBoost tiene ademÃ¡s mayor accuracy y AUC a parte del F1-score, lo cual hace que sean las mejores mÃ©tricas obtenidas de todos los modelos.

Aunque la red neuronal multicapa tambiÃ©n tiene mÃ©tricas buenas, XGBoost las supera y ademÃ¡s suele ser mas rÃ¡pido de entrenar y ajustar que la red neuronal.

En resumen XGBoost balancea bien la detecciÃ³n de cancelaciones que si son cancelaciones (cancelaciones reales) sin generar excesivos errores, lo cual a un hotel o cadena de hoteles le permite reducir mucho las cancelaciones.

**ReflexiÃ³n crÃ­tica sobre limitaciones y mejoras ğŸ¤”**

Hemos identificado que nuestro modelo ofrece buenos resultados, pero son mejorables, ya que tenemos algunas mÃ©tricas que no estÃ¡n en sus mejores valores, por ejemplo el recall, es decir, que no detectamos todas las cancelaciones reales y eso puede afectar a la capacidad del hotel para detectar todas las cancelaciones.

Como mejoras futuras, deberÃ­amos de probar mas tÃ©cnicas de balanceo de clases mejores y hacer otro tipo de pruebas mas avanzadas. Esto nos ayudarÃ­a a predecir mejor y diseÃ±ar estrategias mas fiables para reducir la tasa de cancelaciÃ³n de nuestro hotel.
